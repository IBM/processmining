{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate IBM Process Mining data into IBM Cognos Analytics\n",
    "\n",
    "In most cases, our clients will be using the Dashboard (Analytics) capabilities of IBM Process Mining to broadcast relevant process mining information to managers and employees.\n",
    "\n",
    "They are also typically using extensively a Business Intelligence solution, such as IBM Cognos Analytics, and they can consider that apart from business analysts and process owners, regular employees who are participating in the business process execution should preferably keep using the enterprise BI solution.\n",
    "\n",
    "The following python code shows how we can extract relevant information from IBM Process Mining, and how we can upload this information into IBM Cognos Analytics to create appealing dashboards.\n",
    "\n",
    "The process is the following:\n",
    "\n",
    "- get information from IBM Process Mining by using the IPMClient python library. The information retrieved is a json dict.\n",
    "- transform the json dict into a Pandas dataframe. Sometimes, we need to flatten the json dict and to rename/transform some columns.\n",
    "- save the resulting transformation into a CSV file\n",
    "- upload the CSV file into IBM Cognos Analytics by using the cognos python library\n",
    "\n",
    "## Get the data from Process Mining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPMClient as ipm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ipmConfigFilename = './IPMConfig.json'\n",
    "with open(ipmConfigFilename, 'r') as file:\n",
    "    ipmConfig = json.load(file)  \n",
    "\n",
    "ipmClient = ipm.Client(ipmConfig['url'], ipmConfig['userid'], ipmConfig['apikey'])\n",
    "ipmProject = ipmClient.getProjectByName('Bank Account Closure')    \n",
    "stats = ipmProject.retrieveModelStatistics()\n",
    "processStats = ipmProject.getProcessStatistics(stats)\n",
    "processStats_df = pd.json_normalize(processStats)\n",
    "processStats_df.keys()\n",
    "processStats_df = processStats_df[['minThroughputTime',\n",
    "       'maxThroughputTime', 'avgThroughputTime', 'stdThroughputTime',\n",
    "       'medianThroughputTime', 'minArrivalRate', 'maxArrivalRate',\n",
    "       'avgArrivalRate', 'minTime', 'maxTime', 'filteredCases', 'filteredEvents','totalCases', 'totalEvents']]\n",
    "processStats_df.to_csv('processStats.csv', index=None)\n",
    "\n",
    "activityStats = ipmProject.getActivityStatistics(stats)\n",
    "activityStats_df = pd.json_normalize(activityStats)\n",
    "activityStats_df = activityStats_df[['activityName', 'statistics.frequency', 'statistics.avgDuration', 'statistics.medianDuration', 'statistics.minDuration', 'statistics.maxDuration', 'statistics.caseRepetition', 'statistics.avgRepetition', 'statistics.overallCost']]\n",
    "activityStats_df.rename({'statistics.frequency': 'frequency', 'statistics.avgDuration':'avgDuration', 'statistics.medianDuration':'medianDuration', \n",
    "                         'statistics.minDuration':'minDuration', 'statistics.maxDuration':'maxDuration', 'statistics.caseRepetition':'caseRepetition', \n",
    "                         'statistics.avgRepetition':'avgRepetition', 'statistics.overallCost':'overallCost'}, axis='columns', inplace=True)\n",
    "activityStats_df.to_csv('activityStats.csv', index=None)\n",
    "\n",
    "transitionStats = ipmProject.getTransitionStatistics(stats)\n",
    "transitionStats_df = pd.json_normalize(transitionStats)\n",
    "transitionStats_df.keys()\n",
    "transitionStats_df=transitionStats_df[['sourceActivity', 'targetActivity', 'statistics.frequency', 'statistics.avgDuration', 'statistics.medianDuration',\n",
    "                                       'statistics.minDuration','statistics.maxDuration', 'statistics.parallelFrequency','statistics.caseRepetition','statistics.avgRepetition']]\n",
    "transitionStats_df.rename({'statistics.frequency':'frequency', 'statistics.avgDuration':'avgDuration', 'statistics.medianDuration':'medianDuration',\n",
    "                                       'statistics.minDuration':'minDuration','statistics.maxDuration':'maxDuration', \n",
    "                                       'statistics.parallelFrequency':'parallelFrequency','statistics.caseRepetition':'caseRepetition',\n",
    "                                       'statistics.avgRepetition':'avgRepetition'}, axis='columns', inplace=True)\n",
    "transitionStats_df.to_csv('transitionStats.csv', index=None)\n",
    "\n",
    "dashboard = ipmProject.getDashboardByName('activity stats')\n",
    "widget = dashboard.getWidgetByName('activities')\n",
    "values = widget.retrieveValues()\n",
    "values_df = pd.DataFrame(values)\n",
    "values_df.to_csv('acticityStatsFromWidget.csv', index=None)\n",
    "\n",
    "# RETRIEVE DATA USING PSEUDO SQL. Avoid being limited by the number of rows in a widget\n",
    "\n",
    "query = \"SELECT CASEID, leadtime, casecost(), CLOSURE_TYPE, CLOSURE_REASON, COUNTACTIVITIES, COUNTREWORKS FROM EVENTLOG GROUP BY CASEID\"\n",
    "#res = ipmProject.retrieveFromSQL(query)\n",
    "headers = ipmClient.getHeaders()\n",
    "headers['content-type'] = 'application/x-www-form-urlencoded'\n",
    "data = \"params={'query': '%s'}\" % query\n",
    "res = ipmProject.sendPostRequest(\n",
    "            url=f\"{ipmProject.getURL()}/analytics/integration/{ipmProject.key}/query\",\n",
    "            verify=ipmProject.verify,\n",
    "            params={'org' : ipmProject.organization.key},\n",
    "            headers=headers,\n",
    "            data=data,\n",
    "            files=None,\n",
    "            functionName='retrieve from SQL'\n",
    "        )\n",
    "df = pd.DataFrame(res)\n",
    "df.columns = ['caseid', 'leadtime', 'cost', 'closure_type', 'closure_reason', 'count_activities', 'count_reworks']\n",
    "df.reindex()\n",
    "df['cost'] = df['cost'].apply(lambda x: x[0])\n",
    "df.to_csv('completedCases.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload the data into IBM Cognos Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CognosAnalyticsClient as cog\n",
    "import json\n",
    "class dictToObj ():\n",
    "    def __init__(self, aDict):\n",
    "        self.__dict__.update(aDict)\n",
    "\n",
    "cognosConfigFilename = './CognosAnalytics.json'\n",
    "with open(cognosConfigFilename, 'r') as file:\n",
    "    cognosConfig = json.load(file)\n",
    "\n",
    "\n",
    "cognosCredentials =  cog.cognosCreateCredentials(cognosConfig)    \n",
    "auth = cog.cognosCreateSession(cognosConfig['url'], credentials=cognosCredentials)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='processStats.csv', append=False, silent=False)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='activityStats.csv', append=False, silent=False)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='transitionStats.csv', append=False, silent=False)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='completedCases.csv', append=False, silent=False)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='activityStatsFromWidget.csv', append=False, silent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
