{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Cognos Analytics -- IBM Process Mining\n",
    "## Business Intelligence meets Business Process Intelligence\n",
    "\n",
    "\n",
    "## Collect business performance data for each case\n",
    "Theoritically, we don't yet have process mining data, and we should collect the bank account closure KPIs from the bank's datalake.\n",
    "- a CSV table that lists each case ID with its start date and leadtime in milliseconds\n",
    "- a CSV table that lists each case ID with some business data: CLOSURE_TYPE and CLOSURE_REASON\n",
    "\n",
    "These 2 tables are initially used in Cognos Analytics to display a dashboard with key performance indicators:\n",
    "- Number of requests in 2 years\n",
    "- Average leadtime compared with the EU requirement that is 12 days\n",
    "- Number of requests per type\n",
    "- Evolution of number of requests per day with predictions\n",
    "\n",
    "Since we actually have process mining, we can create these two files using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPMClient as ipm\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "\n",
    "ipmConfigFilename = './IPMConfig.json'\n",
    "with open(ipmConfigFilename, 'r') as file:\n",
    "    ipmConfig = json.load(file)  \n",
    "\n",
    "ipmClient = ipm.Client(ipmConfig['url'], ipmConfig['userid'], ipmConfig['apikey'])\n",
    "ipmProject = ipmClient.getProjectByName('Bank Account Closure')\n",
    "# Apply the filter that exclude running cases   \n",
    "templates = ipmProject.retrieveTemplates()\n",
    "templateId = 0\n",
    "for template in templates:\n",
    "    if template['name'] == 'complete cases':\n",
    "        templateId = template['templateId']\n",
    "        break;\n",
    "templateId\n",
    "\n",
    "# FIRST CSV\n",
    "query = \"SELECT CASEID, MIN(starttime), leadtime FROM EVENTLOG GROUP BY CASEID\"\n",
    "headers = ipmClient.getHeaders()\n",
    "headers['content-type'] = 'application/x-www-form-urlencoded'\n",
    "data = \"params={'templateId': %s, 'query': '%s'}\" % (templateId, query)\n",
    "\n",
    "res = ipmProject.sendPostRequest(\n",
    "            url=f\"{ipmProject.getURL()}/analytics/integration/{ipmProject.key}/query\",\n",
    "            verify=ipmProject.verify,\n",
    "            params={'org' : ipmProject.orgkey},\n",
    "            headers=headers,\n",
    "            data=data,\n",
    "            files=None,\n",
    "            functionName='retrieve from SQL'\n",
    "        )\n",
    "df = pd.DataFrame(res)\n",
    "df.columns = ['caseid', 'startdate', 'leadtime']\n",
    "df.reindex()\n",
    "df['startdate']=df['startdate'].apply(lambda x: dt.fromtimestamp(x[0]/1000))\n",
    "# dates grouped by week\n",
    "df['startdate']=df['startdate'].apply(lambda x: x.replace(day=1, hour=0, minute=0, second=0))\n",
    "\n",
    "df.columns = ['caseid', 'startdate', 'leadtime']\n",
    "df.reindex()\n",
    "df['startdate']=df['startdate'].apply(lambda x: dt.fromtimestamp(x[0]/1000))\n",
    "# dates grouped by week\n",
    "df['startdate']=df['startdate'].apply(lambda x: x.replace(day=1, hour=0, minute=0, second=0))\n",
    "df.to_csv('completedCasesDates.csv', index=None)\n",
    "\n",
    "# SECOND CSV\n",
    "query = \"SELECT CASEID, CLOSURE_TYPE, CLOSURE_REASON FROM EVENTLOG GROUP BY CASEID\"\n",
    "headers = ipmClient.getHeaders()\n",
    "headers['content-type'] = 'application/x-www-form-urlencoded'\n",
    "data = \"params={'templateId': %s, 'query': '%s'}\" % (templateId, query)\n",
    "res = ipmProject.sendPostRequest(\n",
    "            url=f\"{ipmProject.getURL()}/analytics/integration/{ipmProject.key}/query\",\n",
    "            verify=ipmProject.verify,\n",
    "            params={'org' : ipmProject.orgkey},\n",
    "            headers=headers,\n",
    "            data=data,\n",
    "            files=None,\n",
    "            functionName='retrieve from SQL'\n",
    "        )\n",
    "df = pd.DataFrame(res)\n",
    "df.columns = ['caseid', 'closure_type', 'closure_reason']\n",
    "df.reindex()\n",
    "df.to_csv('completedCasesBizData.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load these 2 CSV files into Cognos Analytics\n",
    "Within IBM Cognos Analytics, you can import these 2 files into your content.\n",
    "\n",
    "That can also be done with the Cognos REST API with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CognosAnalyticsClient as cog\n",
    "import json\n",
    "\n",
    "cognosConfigFilename = './CognosAnalytics.json'\n",
    "with open(cognosConfigFilename, 'r') as file:\n",
    "    cognosConfig = json.load(file)\n",
    "\n",
    "\n",
    "cognosCredentials =  cog.cognosCreateCredentials(cognosConfig)    \n",
    "auth = cog.cognosCreateSession(cognosConfig['url'], credentials=cognosCredentials)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='completedCasesDates.csv', append=False, silent=False)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='completedCasesBizData.csv', append=False, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data module in Cognos\n",
    "We create a data module that includes these 2 files.\n",
    "\n",
    "In this data module we:\n",
    "- Join the 2 tables using CASEID\n",
    "- Create a calculation field that transforms the leadtime from milliseconds to days = leadtime/(24*3600000)\n",
    "- Create a calculation field that stores 12 days goal from the EU.\n",
    "- Format the columns nicely\n",
    "\n",
    "## Create a Business Performance dashboard\n",
    "From the data module, we mostly use the Cognos Assistant to create a dashboard like this:\n",
    "\n",
    "<img src=\"./images/business_performance.jpg \" width=\"500\" />\n",
    "## Business Intelligence Meets Business Process Intelligence\n",
    "\n",
    "The performance is not good: 20 days in average instead of 12 days, and the prediction from Cognos shows an increase.\n",
    "\n",
    "What can we do to close bank account closure in less then 12 days?\n",
    "\n",
    "Should we just interview client managers and process owners?\n",
    "\n",
    "Do we have visibility and details about the business process that supports Bank Account Closure?\n",
    "\n",
    "Let's use IBM Process Mining to clearly understand what happends, and to make factual decisions.\n",
    "\n",
    "## IBM Process Mining demo using the Bank Account Closure Project\n",
    "\n",
    "Standard Bank Account Closure demonstration showing frequencies, durations, costs, reworks, variants, compliance, bpmn, and a few dashboards\n",
    "\n",
    "## Enriching Cognos Analytics Dashboards with Process Mining data\n",
    "\n",
    "We now want to share process mining data to a wider audience that is currently Cognos Analytics:\n",
    "- Actions tab: the list of the cases that require an action since they are blocked in a process step for more than a certain time\n",
    "- Process Steps Statistics: The management wants to have statistics of waiting time between each step to fix new goals\n",
    "\n",
    "The code below queries IBM Process Mining to create the CSV files that will be uploaded to IBM Cognos Analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPMClient as ipm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ipmConfigFilename = './IPMConfig.json'\n",
    "with open(ipmConfigFilename, 'r') as file:\n",
    "    ipmConfig = json.load(file)  \n",
    "\n",
    "ipmClient = ipm.Client(ipmConfig['url'], ipmConfig['userid'], ipmConfig['apikey'])\n",
    "proj = ipmClient.getProjectByName('Bank Account Closure')\n",
    "\n",
    "# CSV for Actions. The data is in a table widget in 'Clean The Pipe' dashboard\n",
    "dashboard = proj.getDashboardByName('Clean The Pipe')\n",
    "widgets = dashboard.getWidgets()\n",
    "df = pd.DataFrame(widgets[0].retrieveValues())\n",
    "df.to_csv('blocked_at_pending_liquidation_request.csv', index=None)\n",
    "\n",
    "# CSV for Transition Statistics\n",
    "stats = proj.retrieveModelStatistics()\n",
    "transitionStats = proj.getTransitionStatistics(stats)\n",
    "transitionStats_df = pd.json_normalize(transitionStats)\n",
    "transitionStats_df.keys()\n",
    "transitionStats_df=transitionStats_df[['sourceActivity', 'targetActivity', 'statistics.frequency', 'statistics.avgDuration', 'statistics.medianDuration',\n",
    "                                       'statistics.minDuration','statistics.maxDuration', 'statistics.parallelFrequency','statistics.caseRepetition','statistics.avgRepetition']]\n",
    "transitionStats_df.rename({'statistics.frequency':'frequency', 'statistics.avgDuration':'avgDuration', 'statistics.medianDuration':'medianDuration',\n",
    "                                       'statistics.minDuration':'minDuration','statistics.maxDuration':'maxDuration', \n",
    "                                       'statistics.parallelFrequency':'parallelFrequency','statistics.caseRepetition':'caseRepetition',\n",
    "                                       'statistics.avgRepetition':'avgRepetition'}, axis='columns', inplace=True)\n",
    "transitionStats_df.to_csv('transitionStats.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Process Mining data to Cognos Analytics\n",
    "\n",
    "We now want to upload these 2 files to IBM Cognos Analytics, using the REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CognosAnalyticsClient as cog\n",
    "import json\n",
    "\n",
    "cognosConfigFilename = './CognosAnalytics.json'\n",
    "with open(cognosConfigFilename, 'r') as file:\n",
    "    cognosConfig = json.load(file)\n",
    "\n",
    "\n",
    "cognosCredentials =  cog.cognosCreateCredentials(cognosConfig)    \n",
    "auth = cog.cognosCreateSession(cognosConfig['url'], credentials=cognosCredentials)\n",
    "cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='blocked_at_pending_liquidation_request copy.csv', append=False, silent=False)\n",
    "#cog.cognosUploadFile(cognosConfig['url'], auth['authkey'], auth['authvalue'], filename='transitionStats.csv', append=False, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
